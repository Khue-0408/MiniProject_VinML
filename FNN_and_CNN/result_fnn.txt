fnn_128_hidden_units_0.01_lr_5_epochs.pth
train_loss: [3.849489293132268, 3.7275309321220886, 3.0942426846551556, 2.6386490893533043, 2.3819184334058288]
train_acc: [0.025115820178448867, 0.04382263784031114, 0.12545412948981927, 0.21298959048272706, 0.27272420498741706]
test_loss: [3.841252617690028, 3.290757618793825, 2.574762767269498, 2.168571624017897, 1.909749708208097]
test_acc: [0.050967261904761904, 0.10714285714285714, 0.26372590702947846, 0.3571180555555556, 0.4453550170068027]

--------------------------------------------------
fnn_256_hidden_units_0.01_lr_5_epochs.pth
train_loss: [3.847262615650258, 3.5870763458089625, 2.6642438799607837, 2.106028762337164, 1.7249640613921144]
train_acc: [0.026764470372912377, 0.06508979638526653, 0.21596917181423017, 0.36629775795012587, 0.4750131548844658]
test_loss: [3.832918090074241, 2.8607922901912612, 2.1141321979412417, 1.4836063319120278, 1.201804243078848]
test_acc: [0.051665249433106575, 0.21686507936507937, 0.38800311791383224, 0.5779443027210884, 0.6423575680272109]

--------------------------------------------------
fnn_512_hidden_units_0.01_lr_5_epochs.pth
train_loss: [3.8460728794801318, 3.396712630183984, 2.156142878430955, 1.5586055133697834, 1.2822364744396075]
train_acc: [0.027943548387096773, 0.10906314344543583, 0.36461364676275454, 0.5309096888583847, 0.6059008236101578]
test_loss: [3.830219423284336, 2.373454810405264, 1.5052489853229651, 1.1041976287454165, 0.9295751566485483]
test_acc: [0.12469529478458051, 0.3495712868480726, 0.5662308673469388, 0.6657490079365079, 0.7091021825396826]

--------------------------------------------------
fnn_128_hidden_units_0.1_lr_5_epochs.pth
train_loss: [2.7961079037781302, 1.8805356298947165, 1.6987378044500419, 1.6191994069823137, 1.5687394137247235]
train_acc: [0.20762697323266988, 0.4330908258979639, 0.49111358956760465, 0.5150586250285976, 0.5324959963395104]
test_loss: [1.547574945959915, 1.1681817000617787, 1.1058114175082876, 1.0343762076630885, 1.0010397197539305]
test_acc: [0.5440228174603174, 0.6430661848072562, 0.672530470521542, 0.6739051870748299, 0.6776998299319729]

--------------------------------------------------
fnn_256_hidden_units_0.1_lr_5_epochs.pth
train_loss: [2.4256054549690678, 1.403523490648743, 1.2274310298845277, 1.1487308169003074, 1.0977767576393507]
train_acc: [0.30519103180050333, 0.5685163578128575, 0.6217258636467627, 0.6465302562342713, 0.6618674216426447]
test_loss: [1.157297347881356, 0.8640336933083275, 0.7853873454693223, 0.7351792850563316, 0.7092197447204266]
test_acc: [0.6328373015873016, 0.724826388888889, 0.7457270408163266, 0.7670847505668934, 0.7698022959183674]

--------------------------------------------------
fnn_512_hidden_units_0.1_lr_5_epochs.pth
train_loss: [2.07110489170602, 1.080753622164963, 0.930444303421264, 0.8593321715348156, 0.8110714844651256]
train_acc: [0.4023916151910318, 0.6588629604209563, 0.7046419583619309, 0.7260172157401051, 0.7394043125142988]
test_loss: [0.8895653229282827, 0.6956844240122911, 0.6444756316946072, 0.6063321756363727, 0.5793176592410016]
test_acc: [0.7119508219954649, 0.7755952380952381, 0.7896329365079365, 0.8000425170068027, 0.8082872732426304]

--------------------------------------------------
fnn_128_hidden_units_0.5_lr_5_epochs.pth
train_loss: [3.19137401533465, nan, nan, nan, nan]
train_acc: [0.1377050446122169, 0.023617021276595745, 0.02127745367192862, 0.02127659574468085, 0.02127659574468085]
test_loss: [3.006187608452881, nan, nan, nan, nan]
test_acc: [0.18891723356009069, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397]

--------------------------------------------------
fnn_256_hidden_units_0.5_lr_5_epochs.pth
train_loss: [3.0058748319977564, 3.4566977897941644, 51722672096.48003, 8324840319773.145, 13980853894.140718]
train_acc: [0.19619051704415463, 0.1208427705330588, 0.049885609700297415, 0.021391843971631207, 0.02022163120567376]
test_loss: [2.5735702431526315, 3.491454626021742, 3.853518868790192, 3.853588441196753, 3.853313308183839]
test_acc: [0.31693948412698414, 0.08961167800453515, 0.021318735827664397, 0.021318735827664397, 0.021258503401360544]

--------------------------------------------------
fnn_512_hidden_units_0.5_lr_5_epochs.pth
train_loss: [2.7944932955207555, 3.449118508075146, 3.688545263980297, 3.6637241377729053, 3.7800534449232384]
train_acc: [0.2592221459620224, 0.15091397849462365, 0.0549027682452528, 0.044398021047815144, 0.031054964539007093]
test_loss: [2.268618788646192, 3.417508370616809, 3.6567575031397292, 3.885136912874624, 3.862260734953848]
test_acc: [0.3790887188208617, 0.11969954648526078, 0.039965986394557826, 0.021903344671201815, 0.021258503401360544]

--------------------------------------------------
fnn_128_hidden_units_0.01_lr_10_epochs.pth
train_loss: [3.849489293132268, 3.7275309321220886, 3.0942426846551556, 2.6386490893533043, 2.3819184334058288, 2.1966785159347753, 2.055104733155974, 1.9458619949327294, 1.861808886798561, 1.802358058936207]
train_acc: [0.025115820178448867, 0.04382263784031114, 0.12545412948981927, 0.21298959048272706, 0.27272420498741706, 0.32497654998856096, 0.3659431480210478, 0.39861902310684055, 0.42411805078929304, 0.4433001601464196]
test_loss: [3.841252617690028, 3.290757618793825, 2.574762767269498, 2.168571624017897, 1.909749708208097, 1.7156452309517634, 1.5527245175270807, 1.457610467360133, 1.378430230479662, 1.3089550577458882]
test_acc: [0.050967261904761904, 0.10714285714285714, 0.26372590702947846, 0.3571180555555556, 0.4453550170068027, 0.5121138038548753, 0.5510841836734695, 0.5661918934240363, 0.5908517573696145, 0.6184275793650794]

--------------------------------------------------
fnn_256_hidden_units_0.01_lr_10_epochs.pth
train_loss: [3.847262615650258, 3.5870763458089625, 2.6642438799607837, 2.106028762337164, 1.7249640613921144, 1.5237803889842743, 1.39651522071649, 1.3122208852125399, 1.2474173664201236, 1.1894856820123416]
train_acc: [0.026764470372912377, 0.06508979638526653, 0.21596917181423017, 0.36629775795012587, 0.4750131548844658, 0.5325408945321436, 0.5695181308625029, 0.5936401853122855, 0.6101212537176847, 0.6290848776023794]
test_loss: [3.832918090074241, 2.8607922901912612, 2.1141321979412417, 1.4836063319120278, 1.201804243078848, 1.0642862918020106, 0.9807118430835049, 0.9093054323678925, 0.8631047323143402, 0.8218647414425604]
test_acc: [0.051665249433106575, 0.21686507936507937, 0.38800311791383224, 0.5779443027210884, 0.6423575680272109, 0.6822704081632653, 0.6980477607709751, 0.7145762471655329, 0.7318416950113379, 0.7426906179138322]

--------------------------------------------------
fnn_512_hidden_units_0.01_lr_10_epochs.pth
train_loss: [3.8460728794801318, 3.396712630183984, 2.156142878430955, 1.5586055133697834, 1.2822364744396075, 1.132039535003351, 1.0385311646918034, 0.9661408138190601, 0.912656123908699, 0.8762238358267656]
train_acc: [0.027943548387096773, 0.10906314344543583, 0.36461364676275454, 0.5309096888583847, 0.6059008236101578, 0.6470192747654999, 0.6730896819949668, 0.6950326012354152, 0.7096785632578356, 0.7223916151910319]
test_loss: [3.830219423284336, 2.373454810405264, 1.5052489853229651, 1.1041976287454165, 0.9295751566485483, 0.82258627660015, 0.7660517089930522, 0.7099923065730503, 0.675788323464645, 0.6520532577418957]
test_acc: [0.12469529478458051, 0.3495712868480726, 0.5662308673469388, 0.6657490079365079, 0.7091021825396826, 0.7454010770975057, 0.754389880952381, 0.7730371315192744, 0.7835140306122449, 0.7856327947845805]

--------------------------------------------------
fnn_128_hidden_units_0.1_lr_10_epochs.pth
train_loss: [2.7961079037781302, 1.8805356298947165, 1.6987378044500419, 1.6191994069823137, 1.5687394137247235, 1.5437059069187082, 1.5089362137199294, 1.4933003610245725, 1.480861692293316, 1.4750019160737382]
train_acc: [0.20762697323266988, 0.4330908258979639, 0.49111358956760465, 0.5150586250285976, 0.5324959963395104, 0.5391615191031801, 0.552744223289865, 0.555440402653855, 0.5623813200640585, 0.5647649279341111]
test_loss: [1.547574945959915, 1.1681817000617787, 1.1058114175082876, 1.0343762076630885, 1.0010397197539305, 0.9641249779941273, 0.9652784235116576, 0.9430116543254885, 0.9548167079484382, 0.932141050696373]
test_acc: [0.5440228174603174, 0.6430661848072562, 0.672530470521542, 0.6739051870748299, 0.6776998299319729, 0.6980477607709751, 0.7000814909297052, 0.7046981292517007, 0.6974631519274377, 0.7074475623582767]

--------------------------------------------------
fnn_256_hidden_units_0.1_lr_10_epochs.pth
train_loss: [2.4256054549690678, 1.403523490648743, 1.2274310298845277, 1.1487308169003074, 1.0977767576393507, 1.069759428847766, 1.0465988609680892, 1.0240446063897288, 1.013834476842948, 1.00279360266442]
train_acc: [0.30519103180050333, 0.5685163578128575, 0.6217258636467627, 0.6465302562342713, 0.6618674216426447, 0.6713194921070693, 0.6785000571951499, 0.6839604781514527, 0.6884462937542896, 0.6920636010066347]
test_loss: [1.157297347881356, 0.8640336933083275, 0.7853873454693223, 0.7351792850563316, 0.7092197447204266, 0.6926490486580499, 0.6836031814720355, 0.6672515867113256, 0.6514069911117862, 0.6581798304303162]
test_acc: [0.6328373015873016, 0.724826388888889, 0.7457270408163266, 0.7670847505668934, 0.7698022959183674, 0.7767183956916099, 0.7798008786848073, 0.7833475056689343, 0.7891014739229025, 0.7850623582766441]

--------------------------------------------------
fnn_512_hidden_units_0.1_lr_10_epochs.pth
train_loss: [2.07110489170602, 1.080753622164963, 0.930444303421264, 0.8593321715348156, 0.8110714844651256, 0.7823902458586591, 0.7567330547469727, 0.7413314101459286, 0.7220884385345675, 0.7124906882580291]
train_acc: [0.4023916151910318, 0.6588629604209563, 0.7046419583619309, 0.7260172157401051, 0.7394043125142988, 0.7480659460077785, 0.7555213337908946, 0.7601043811484787, 0.7663189201555709, 0.7693339624799818]
test_loss: [0.8895653229282827, 0.6956844240122911, 0.6444756316946072, 0.6063321756363727, 0.5793176592410016, 0.5491108027901374, 0.5346733991588865, 0.5237627651314346, 0.512723756282508, 0.5095835193788925]
test_acc: [0.7119508219954649, 0.7755952380952381, 0.7896329365079365, 0.8000425170068027, 0.8082872732426304, 0.8147640306122449, 0.8188031462585034, 0.8214675453514739, 0.824390589569161, 0.82203089569161]

--------------------------------------------------
fnn_128_hidden_units_0.5_lr_10_epochs.pth
train_loss: [3.19137401533465, nan, nan, nan, nan, nan, nan, nan, nan, nan]
train_acc: [0.1377050446122169, 0.023617021276595745, 0.02127745367192862, 0.02127659574468085, 0.02127659574468085, 0.02127659574468085, 0.02127659574468085, 0.02127659574468085, 0.02127659574468085, 0.021277167696179364]
test_loss: [3.006187608452881, nan, nan, nan, nan, nan, nan, nan, nan, nan]
test_acc: [0.18891723356009069, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397]

--------------------------------------------------
fnn_256_hidden_units_0.5_lr_10_epochs.pth
train_loss: [3.0058748319977564, 3.4566977897941644, 51722672096.48003, 8324840319773.145, 13980853894.140718, 3.853894682674543, 3.854160146510347, 3.8538714536031087, 3.8540704185404677, 3.8541180754046067]
train_acc: [0.19619051704415463, 0.1208427705330588, 0.049885609700297415, 0.021391843971631207, 0.02022163120567376, 0.02205673758865248, 0.02119738046213681, 0.021843971631205675, 0.02074468085106383, 0.020469858156028368]
test_loss: [2.5735702431526315, 3.491454626021742, 3.853518868790192, 3.853588441196753, 3.853313308183839, 3.8538350102041856, 3.8535153411683583, 3.8540005379793594, 3.8532884493977035, 3.852796679856826]
test_acc: [0.31693948412698414, 0.08961167800453515, 0.021318735827664397, 0.021318735827664397, 0.021258503401360544, 0.021258503401360544, 0.021258503401360544, 0.021258503401360544, 0.021258503401360544, 0.021258503401360544]

--------------------------------------------------
fnn_512_hidden_units_0.5_lr_10_epochs.pth
train_loss: [2.7944932955207555, 3.449118508075146, 3.688545263980297, 3.6637241377729053, 3.7800534449232384, 3.7723247106700923, 3.7774540136215533, 3.7699630551980743, 3.7674147500383093, 3.7815434783232127]
train_acc: [0.2592221459620224, 0.15091397849462365, 0.0549027682452528, 0.044398021047815144, 0.031054964539007093, 0.031471631205673756, 0.029504118050789292, 0.029388297872340426, 0.03162262640128117, 0.03052304964539007]
test_loss: [2.268618788646192, 3.417508370616809, 3.6567575031397292, 3.885136912874624, 3.862260734953848, 3.8717785384379275, 3.858835286429139, 3.8667043252867095, 3.8696542686345627, 3.867185729701503]
test_acc: [0.3790887188208617, 0.11969954648526078, 0.039965986394557826, 0.021903344671201815, 0.021258503401360544, 0.021205357142857144, 0.021258503401360544, 0.021258503401360544, 0.021258503401360544, 0.021258503401360544]

--------------------------------------------------
fnn_128_hidden_units_0.01_lr_20_epochs.pth
train_loss: [3.849489293132268, 3.7275309321220886, 3.0942426846551556, 2.6386490893533043, 2.3819184334058288, 2.1966785159347753, 2.055104733155974, 1.9458619949327294, 1.861808886798561, 1.802358058936207, 1.7425142771808813, 1.7004667128231508, 1.6570700889276275, 1.6205580076596415, 1.5823464877047437, 1.5545624247341292, 1.5249544745134123, 1.4991893693910423, 1.4742815422504507, 1.4578993977553456]
train_acc: [0.025115820178448867, 0.04382263784031114, 0.12545412948981927, 0.21298959048272706, 0.27272420498741706, 0.32497654998856096, 0.3659431480210478, 0.39861902310684055, 0.42411805078929304, 0.4433001601464196, 0.4627793983070236, 0.4733816632349577, 0.486704987417067, 0.49767358727979866, 0.5114845001143903, 0.5200826469915351, 0.5326035232212308, 0.5396934339967971, 0.549243880118966, 0.5527530885380919]
test_loss: [3.841252617690028, 3.290757618793825, 2.574762767269498, 2.168571624017897, 1.909749708208097, 1.7156452309517634, 1.5527245175270807, 1.457610467360133, 1.378430230479662, 1.3089550577458882, 1.2595419869536446, 1.2080696785733813, 1.1768952213785275, 1.1409286611339673, 1.1039432289243556, 1.0831996980978518, 1.0448417868338475, 1.0221886740249841, 0.9973151629068413, 0.9843434816112324]
test_acc: [0.050967261904761904, 0.10714285714285714, 0.26372590702947846, 0.3571180555555556, 0.4453550170068027, 0.5121138038548753, 0.5510841836734695, 0.5661918934240363, 0.5908517573696145, 0.6184275793650794, 0.6260948129251701, 0.6431476757369615, 0.6481044501133787, 0.6515979308390023, 0.6637755102040817, 0.67328160430839, 0.6896967120181406, 0.693484268707483, 0.6968785430839003, 0.7018601190476191]

--------------------------------------------------
fnn_256_hidden_units_0.01_lr_20_epochs.pth
train_loss: [3.847262615650258, 3.5870763458089625, 2.6642438799607837, 2.106028762337164, 1.7249640613921144, 1.5237803889842743, 1.39651522071649, 1.3122208852125399, 1.2474173664201236, 1.1894856820123416, 1.1450824916700946, 1.1135126164872595, 1.078161485905343, 1.0507321678408494, 1.0259536638919344, 1.0013339625859092, 0.983364095442684, 0.9646153301719232, 0.9514458962450636, 0.9350015727848026]
train_acc: [0.026764470372912377, 0.06508979638526653, 0.21596917181423017, 0.36629775795012587, 0.4750131548844658, 0.5325408945321436, 0.5695181308625029, 0.5936401853122855, 0.6101212537176847, 0.6290848776023794, 0.6431537405628002, 0.6533487760237932, 0.6609991992679021, 0.6705373484328528, 0.6787459963395104, 0.6860621139327385, 0.6911235987188286, 0.6963875543353923, 0.7007781400137268, 0.7066632349576756]
test_loss: [3.832918090074241, 2.8607922901912612, 2.1141321979412417, 1.4836063319120278, 1.201804243078848, 1.0642862918020106, 0.9807118430835049, 0.9093054323678925, 0.8631047323143402, 0.8218647414425604, 0.7935874961874112, 0.7738514176639569, 0.74494261578435, 0.7326125031223103, 0.7127013069634535, 0.7031938287676597, 0.6849305030135882, 0.6752340835677523, 0.6674623812998639, 0.6597231721543536]
test_acc: [0.051665249433106575, 0.21686507936507937, 0.38800311791383224, 0.5779443027210884, 0.6423575680272109, 0.6822704081632653, 0.6980477607709751, 0.7145762471655329, 0.7318416950113379, 0.7426906179138322, 0.7488024376417234, 0.7564625850340136, 0.7634708049886622, 0.7639420351473923, 0.7713364512471655, 0.7778202947845805, 0.7803784013605443, 0.7838860544217687, 0.7811755952380952, 0.7880846088435375]

--------------------------------------------------
fnn_512_hidden_units_0.01_lr_20_epochs.pth
train_loss: [3.8460728794801318, 3.396712630183984, 2.156142878430955, 1.5586055133697834, 1.2822364744396075, 1.132039535003351, 1.0385311646918034, 0.9661408138190601, 0.912656123908699, 0.8762238358267656, 0.8397109234840312, 0.8091610798937209, 0.7863819618258916, 0.7649185876262948, 0.7394015638583096, 0.7278034987855465, 0.7086325633610394, 0.6962594106899086, 0.6865319855669711, 0.6710807964015514]
train_acc: [0.027943548387096773, 0.10906314344543583, 0.36461364676275454, 0.5309096888583847, 0.6059008236101578, 0.6470192747654999, 0.6730896819949668, 0.6950326012354152, 0.7096785632578356, 0.7223916151910319, 0.7306986387554336, 0.7393425417524594, 0.7464876458476322, 0.750751544269046, 0.7598824639670555, 0.763748856097003, 0.7671699839853581, 0.7700520475863647, 0.7742181423015329, 0.7780648021047815]
test_loss: [3.830219423284336, 2.373454810405264, 1.5052489853229651, 1.1041976287454165, 0.9295751566485483, 0.82258627660015, 0.7660517089930522, 0.7099923065730503, 0.675788323464645, 0.6520532577418957, 0.6272174913410832, 0.6133637874811685, 0.5955699527648841, 0.5856610257812098, 0.5737132071739152, 0.5574517316964208, 0.560033905085455, 0.5451577635748046, 0.5389166373987587, 0.530150465261774]
test_acc: [0.12469529478458051, 0.3495712868480726, 0.5662308673469388, 0.6657490079365079, 0.7091021825396826, 0.7454010770975057, 0.754389880952381, 0.7730371315192744, 0.7835140306122449, 0.7856327947845805, 0.8008326247165534, 0.8003011621315193, 0.8041808390022676, 0.8100871598639456, 0.810186366213152, 0.8156072845804989, 0.8131164965986395, 0.8191149376417234, 0.8168296485260771, 0.8235933956916099]

--------------------------------------------------
fnn_128_hidden_units_0.1_lr_20_epochs.pth
train_loss: [2.7961079037781302, 1.8805356298947165, 1.6987378044500419, 1.6191994069823137, 1.5687394137247235, 1.5437059069187082, 1.5089362137199294, 1.4933003610245725, 1.480861692293316, 1.4750019160737382, 1.4608834133249649, 1.451560142378435, 1.4433961329054326, 1.4439918165680365, 1.4357587550717887, 1.4289782869562189, 1.4318088746747226, 1.420237177787943, 1.4085849664059091, 1.4171460098239548]
train_acc: [0.20762697323266988, 0.4330908258979639, 0.49111358956760465, 0.5150586250285976, 0.5324959963395104, 0.5391615191031801, 0.552744223289865, 0.555440402653855, 0.5623813200640585, 0.5647649279341111, 0.5693654198124, 0.5717327270647449, 0.575563086250286, 0.5745352894074582, 0.5786316060398079, 0.5774345115534203, 0.5781162777396477, 0.5830004575611988, 0.5862113932738503, 0.5862645847632121]
test_loss: [1.547574945959915, 1.1681817000617787, 1.1058114175082876, 1.0343762076630885, 1.0010397197539305, 0.9641249779941273, 0.9652784235116576, 0.9430116543254885, 0.9548167079484382, 0.932141050696373, 0.91862667914556, 0.9149081953832893, 0.916662089475969, 0.9064081176405862, 0.8987241417777782, 0.891030361711168, 0.910410942421073, 0.9060704475458787, 0.8764775402489162, 0.8806524297007087]
test_acc: [0.5440228174603174, 0.6430661848072562, 0.672530470521542, 0.6739051870748299, 0.6776998299319729, 0.6980477607709751, 0.7000814909297052, 0.7046981292517007, 0.6974631519274377, 0.7074475623582767, 0.7076211734693878, 0.7138924319727892, 0.7076672335600908, 0.7140979308390023, 0.7106575963718821, 0.7206349206349206, 0.7143494897959184, 0.7095875850340136, 0.7182964852607711, 0.7225552721088435]

--------------------------------------------------
fnn_256_hidden_units_0.1_lr_20_epochs.pth
train_loss: [2.4256054549690678, 1.403523490648743, 1.2274310298845277, 1.1487308169003074, 1.0977767576393507, 1.069759428847766, 1.0465988609680892, 1.0240446063897288, 1.013834476842948, 1.00279360266442, 0.989686830288975, 0.9779938833848805, 0.9712120822389075, 0.9612285301786788, 0.9536193501864765, 0.9504427931917475, 0.9474506865579185, 0.9404021027916712, 0.9310870945791826, 0.9266400743714461]
train_acc: [0.30519103180050333, 0.5685163578128575, 0.6217258636467627, 0.6465302562342713, 0.6618674216426447, 0.6713194921070693, 0.6785000571951499, 0.6839604781514527, 0.6884462937542896, 0.6920636010066347, 0.6954249599633952, 0.6998378517501715, 0.701407286662091, 0.7046608327613818, 0.7071256577442233, 0.7082609814687715, 0.710263097689316, 0.7128260123541524, 0.7144566460764127, 0.7162296957218027]
test_loss: [1.157297347881356, 0.8640336933083275, 0.7853873454693223, 0.7351792850563316, 0.7092197447204266, 0.6926490486580499, 0.6836031814720355, 0.6672515867113256, 0.6514069911117862, 0.6581798304303162, 0.6487784160136365, 0.6445924497532601, 0.6281651871240869, 0.6362896754222662, 0.6206951728534131, 0.6239517776637661, 0.6205859609252337, 0.6156718467875403, 0.6210957851995822, 0.6123611027894377]
test_acc: [0.6328373015873016, 0.724826388888889, 0.7457270408163266, 0.7670847505668934, 0.7698022959183674, 0.7767183956916099, 0.7798008786848073, 0.7833475056689343, 0.7891014739229025, 0.7850623582766441, 0.7812287414965987, 0.7814873866213152, 0.7963754251700681, 0.7911670918367347, 0.7989264455782313, 0.7996173469387755, 0.7976509353741497, 0.8007794784580499, 0.7917977607709751, 0.8007405045351474]

--------------------------------------------------
fnn_512_hidden_units_0.1_lr_20_epochs.pth
train_loss: [2.07110489170602, 1.080753622164963, 0.930444303421264, 0.8593321715348156, 0.8110714844651256, 0.7823902458586591, 0.7567330547469727, 0.7413314101459286, 0.7220884385345675, 0.7124906882580291, 0.702469170224582, 0.6944155300382181, 0.6876567850425733, 0.6792918150813867, 0.6684865379333496, 0.6650868762807643, 0.6583546597906884, 0.6584925481296601, 0.6473314810475559, 0.6488427366348023]
train_acc: [0.4023916151910318, 0.6588629604209563, 0.7046419583619309, 0.7260172157401051, 0.7394043125142988, 0.7480659460077785, 0.7555213337908946, 0.7601043811484787, 0.7663189201555709, 0.7693339624799818, 0.7712128231525968, 0.7740680050331732, 0.7756628917867765, 0.7777013269274765, 0.7819655113246397, 0.7820736101578586, 0.7845467284374286, 0.7855928277282087, 0.7888097689315945, 0.7865765843056509]
test_loss: [0.8895653229282827, 0.6956844240122911, 0.6444756316946072, 0.6063321756363727, 0.5793176592410016, 0.5491108027901374, 0.5346733991588865, 0.5237627651314346, 0.512723756282508, 0.5095835193788925, 0.5156087295031871, 0.49619569353201765, 0.4937608343910198, 0.48769928390781087, 0.4901880456679532, 0.47824398349641134, 0.4755856009567676, 0.48347495963834985, 0.4834989579964657, 0.4746277925184592]
test_acc: [0.7119508219954649, 0.7755952380952381, 0.7896329365079365, 0.8000425170068027, 0.8082872732426304, 0.8147640306122449, 0.8188031462585034, 0.8214675453514739, 0.824390589569161, 0.82203089569161, 0.8228954081632653, 0.8254003684807256, 0.8308212868480725, 0.832688492063492, 0.8310338718820862, 0.8348604024943311, 0.83468679138322, 0.8340029761904763, 0.8243764172335601, 0.8399092970521542]

--------------------------------------------------
fnn_128_hidden_units_0.5_lr_20_epochs.pth
train_loss: [3.19137401533465, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]
train_acc: [0.1377050446122169, 0.023617021276595745, 0.02127745367192862, 0.02127659574468085, 0.02127659574468085, 0.02127659574468085, 0.02127659574468085, 0.02127659574468085, 0.02127659574468085, 0.021277167696179364, 0.02127659574468085, 0.02127659574468085, 0.02127659574468085, 0.021277167696179364, 0.02127659574468085, 0.02127688172043011, 0.02127688172043011, 0.021277167696179364, 0.02127688172043011, 0.02127688172043011]
test_loss: [3.006187608452881, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]
test_acc: [0.18891723356009069, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397, 0.021318735827664397]

--------------------------------------------------
fnn_256_hidden_units_0.5_lr_20_epochs.pth
train_loss: [3.0058748319977564, 3.4566977897941644, 51722672096.48003, 8324840319773.145, 13980853894.140718, 3.853894682674543, 3.854160146510347, 3.8538714536031087, 3.8540704185404677, 3.8541180754046067, 3.854186720746629, 3.8542260356659583, 3.8540544866331925, 3.854150849673765, 3.854071912494957, 3.8539557356191865, 3.8543280928185646, 3.8541265375394347, 3.8541454547855025, 3.8539039055168205]
train_acc: [0.19619051704415463, 0.1208427705330588, 0.049885609700297415, 0.021391843971631207, 0.02022163120567376, 0.02205673758865248, 0.02119738046213681, 0.021843971631205675, 0.02074468085106383, 0.020469858156028368, 0.020913120567375886, 0.021454186684969113, 0.0212145390070922, 0.020665465568519788, 0.021613475177304966, 0.021622340425531916, 0.020975463280713796, 0.02078900709219858, 0.020753832075040037, 0.02199468085106383]
test_loss: [2.5735702431526315, 3.491454626021742, 3.853518868790192, 3.853588441196753, 3.853313308183839, 3.8538350102041856, 3.8535153411683583, 3.8540005379793594, 3.8532884493977035, 3.852796679856826, 3.854842876901432, 3.8537169009649834, 3.853559896654012, 3.853826494849458, 3.855507782121905, 3.855619874130301, 3.8542890690621876, 3.854963621720165, 3.8528288306833125, 3.854594815750511]
test_acc: [0.31693948412698414, 0.08961167800453515, 0.021318735827664397, 0.021318735827664397, 0.021258503401360544, 0.021258503401360544, 0.021258503401360544, 0.021258503401360544, 0.021258503401360544, 0.021258503401360544, 0.021258503401360544, 0.021318735827664397, 0.021258503401360544, 0.021258503401360544, 0.021258503401360544, 0.021318735827664397, 0.021318735827664397, 0.021258503401360544, 0.021258503401360544, 0.021258503401360544]

--------------------------------------------------
fnn_512_hidden_units_0.5_lr_20_epochs.pth
train_loss: [2.7944932955207555, 3.449118508075146, 3.688545263980297, 3.6637241377729053, 3.7800534449232384, 3.7723247106700923, 3.7774540136215533, 3.7699630551980743, 3.7674147500383093, 3.7815434783232127, 3.7659807561644425, 3.80417764054968, 3.820871864413539, 3.820975276189493, 3.822978541597407, 3.8287202390034993, 3.834875397648372, 3.8348449856507862, 3.8433580000180725, 3.844155536002301]
train_acc: [0.2592221459620224, 0.15091397849462365, 0.0549027682452528, 0.044398021047815144, 0.031054964539007093, 0.031471631205673756, 0.029504118050789292, 0.029388297872340426, 0.03162262640128117, 0.03052304964539007, 0.03001830244795241, 0.027624113475177306, 0.025301990391214824, 0.02507120796156486, 0.024494966826813087, 0.02384780370624571, 0.023457446808510637, 0.023289007092198583, 0.021861702127659574, 0.02132120796156486]
test_loss: [2.268618788646192, 3.417508370616809, 3.6567575031397292, 3.885136912874624, 3.862260734953848, 3.8717785384379275, 3.858835286429139, 3.8667043252867095, 3.8696542686345627, 3.867185729701503, 3.882201765670257, 3.859520266250688, 3.8563495108059476, 3.8554665028643447, 3.8558967287848596, 3.8540567382663284, 3.853562827418451, 3.854342082730767, 3.8541367025602433, 3.854054315966003]
test_acc: [0.3790887188208617, 0.11969954648526078, 0.039965986394557826, 0.021903344671201815, 0.021258503401360544, 0.021205357142857144, 0.021258503401360544, 0.021258503401360544, 0.021258503401360544, 0.021258503401360544, 0.021258503401360544, 0.021318735827664397, 0.021258503401360544, 0.021378968253968254, 0.021258503401360544, 0.021318735827664397, 0.021258503401360544, 0.021258503401360544, 0.021205357142857144, 0.021378968253968254]

--------------------------------------------------
